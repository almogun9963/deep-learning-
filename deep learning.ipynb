{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Almog\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Almog\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Almog\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Almog\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Almog\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Almog\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Almog\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Almog\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Almog\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Almog\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Almog\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Almog\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the dataset\n",
    "data=pd.read_csv(r\"C:\\Users\\Almog\\titanic_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping not concerned columns\n",
    "def drop_not_concerned(data, columns):\n",
    "    return data.drop(columns, axis=1)\n",
    "\n",
    "columns = [\"PassengerId\",\"Name\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"]\n",
    "data = drop_not_concerned(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the empty spots in test dataset\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignoting the empty spots in test dataset\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of the data \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting the Pclass into 3 diffrents columns\n",
    "def dummy_data(data, columns):\n",
    "    for column in columns:\n",
    "        data = pd.concat([data, pd.get_dummies(data[column], prefix=column)], axis=1)\n",
    "        data = data.drop(column, axis=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "columns = [\"Pclass\"]\n",
    "data=dummy_data(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the 'sex' column into 0,1 (0=female, 1=male)\n",
    "def sex_to_int(data):\n",
    "    le = LabelEncoder()\n",
    "    le.fit([\"male\",\"female\"])\n",
    "    data[\"Sex\"]=le.transform(data[\"Sex\"]) \n",
    "    return data\n",
    "\n",
    "data = sex_to_int(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the data\n",
    "def normalize_age(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    data[\"Age\"] = scaler.fit_transform(data[\"Age\"].values.reshape(-1,1))\n",
    "    return data\n",
    "data = normalize_age(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Sex       Age  SibSp  Parch  Pclass_1  Pclass_2  Pclass_3\n",
       "0         0    1  0.271174      1      0         0         0         1\n",
       "1         1    0  0.472229      1      0         1         0         0\n",
       "2         1    0  0.321438      0      0         0         0         1\n",
       "3         1    0  0.434531      1      0         1         0         0\n",
       "4         0    1  0.434531      0      0         0         0         1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the data after the cleaning\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up y label\n",
    "y= data['Survived']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex       Age  SibSp  Parch  Pclass_1  Pclass_2  Pclass_3\n",
       "0    1  0.271174      1      0         0         0         1\n",
       "1    0  0.472229      1      0         1         0         0\n",
       "2    0  0.321438      0      0         0         0         1\n",
       "3    0  0.434531      1      0         1         0         0\n",
       "4    1  0.434531      0      0         0         0         1"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up x label, aka the features\n",
    "X = data.drop(['Survived'],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the x and y train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X ,y, test_size=0.25 ,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(535, 7)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 7)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(535,)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values.reshape((535,1))\n",
    "y_test = y_test.values.reshape((179,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(535, 1)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0  W: [[-6.4730784e-04]\n",
      " [-1.9822811e-04]\n",
      " [-2.6903828e-04]\n",
      " [-1.3390415e-04]\n",
      " [ 2.6218560e-05]\n",
      " [-8.7790140e-05]\n",
      " [-4.5252059e-04]]  b: [-0.00051409]  loss: 0.7655632\n",
      "accuracy 0.6256983\n",
      "Iteration: 10000  W: [[-1.9747176 ]\n",
      " [-0.17084813]\n",
      " [-0.07076117]\n",
      " [ 0.18151355]\n",
      " [ 0.7325912 ]\n",
      " [ 0.12443284]\n",
      " [-1.1507663 ]]  b: [-0.29374278]  loss: 0.65959215\n",
      "accuracy 0.7318436\n",
      "Iteration: 20000  W: [[-2.9072788 ]\n",
      " [-0.12275955]\n",
      " [-0.04666103]\n",
      " [ 0.17684908]\n",
      " [ 1.2080294 ]\n",
      " [ 0.41913518]\n",
      " [-1.5592222 ]]  b: [0.06794298]  loss: 0.64446807\n",
      "accuracy 0.8044693\n",
      "Iteration: 30000  W: [[-3.5858989 ]\n",
      " [-0.12978537]\n",
      " [-0.06499355]\n",
      " [ 0.13005745]\n",
      " [ 1.4687114 ]\n",
      " [ 0.6472271 ]\n",
      " [-1.8182995 ]]  b: [0.29764152]  loss: 0.6373763\n",
      "accuracy 0.8044693\n",
      "Iteration: 40000  W: [[-4.109639  ]\n",
      " [-0.15258901]\n",
      " [-0.08540729]\n",
      " [ 0.09591416]\n",
      " [ 1.6457933 ]\n",
      " [ 0.8242004 ]\n",
      " [-2.0072246 ]]  b: [0.46275985]  loss: 0.6333355\n",
      "accuracy 0.8044693\n",
      "Iteration: 50000  W: [[-4.5327325 ]\n",
      " [-0.17982674]\n",
      " [-0.104333  ]\n",
      " [ 0.07161789]\n",
      " [ 1.7821918 ]\n",
      " [ 0.96606714]\n",
      " [-2.1573799 ]]  b: [0.5908636]  loss: 0.630743\n",
      "accuracy 0.8044693\n",
      "Iteration: 60000  W: [[-4.886165  ]\n",
      " [-0.2079275 ]\n",
      " [-0.12126806]\n",
      " [ 0.05342951]\n",
      " [ 1.8945262 ]\n",
      " [ 1.0836365 ]\n",
      " [-2.2828305 ]]  b: [0.6953319]  loss: 0.62894464\n",
      "accuracy 0.8044693\n",
      "Iteration: 70000  W: [[-5.1889896 ]\n",
      " [-0.23564985]\n",
      " [-0.13632807]\n",
      " [ 0.03918089]\n",
      " [ 1.9906793 ]\n",
      " [ 1.1837304 ]\n",
      " [-2.390888  ]]  b: [0.7835277]  loss: 0.6276261\n",
      "accuracy 0.8044693\n",
      "Iteration: 80000  W: [[-5.453567  ]\n",
      " [-0.2625754 ]\n",
      " [-0.14977469]\n",
      " [ 0.02762876]\n",
      " [ 2.0750682 ]\n",
      " [ 1.270795  ]\n",
      " [-2.485964  ]]  b: [0.8598909]  loss: 0.6266185\n",
      "accuracy 0.8044693\n",
      "Iteration: 90000  W: [[-5.6883826 ]\n",
      " [-0.28860012]\n",
      " [-0.16186883]\n",
      " [ 0.01801644]\n",
      " [ 2.1503413 ]\n",
      " [ 1.3477424 ]\n",
      " [-2.5708053 ]]  b: [0.9273015]  loss: 0.62582403\n",
      "accuracy 0.8044693\n"
     ]
    }
   ],
   "source": [
    "#simple logistic regression\n",
    "features = 7\n",
    "x = tf.placeholder(tf.float32, [None, features])\n",
    "y_ = tf.placeholder(tf.float32, [None, 1])\n",
    "W = tf.Variable(tf.zeros([features,1]))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "y = tf.nn.sigmoid(tf.matmul(x,W) + b)\n",
    "#loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=tf.add(tf.matmul(x, W), b), labels=y_))\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y, labels=y_))\n",
    "\n",
    "prediction = tf.round(y)\n",
    "correct = tf.cast(tf.equal(prediction, y_), dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(correct)\n",
    "\n",
    "update = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(0,100000):\n",
    "    sess.run(update, feed_dict = {x:x_train, y_:y_train})\n",
    "    trainAcc = sess.run(accuracy, feed_dict={x: x_test, y_: y_test})\n",
    "    if i % 10000 == 0 :\n",
    "        print('Iteration:' , i , ' W:' , sess.run(W) , ' b:' , sess.run(b), ' loss:', loss.eval(session=sess, feed_dict = {x:x_train, y_:y_train}))\n",
    "        print('accuracy',trainAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0  W: [[ 0.07643595]\n",
      " [ 0.15534988]\n",
      " [-0.01552953]]  b: -9.028719e-06  loss: 0.6967314\n",
      "accuracy 0.37430167\n",
      "Iteration: 100000  W: [[ 0.19761905]\n",
      " [ 0.19901118]\n",
      " [-0.12047128]]  b: -0.30990177  loss: 0.66822135\n",
      "accuracy 0.6256983\n",
      "Iteration: 200000  W: [[ 0.60525835]\n",
      " [ 0.50347954]\n",
      " [-0.5053719 ]]  b: -0.36393824  loss: 0.58094823\n",
      "accuracy 0.7430168\n",
      "Iteration: 300000  W: [[ 1.0097117 ]\n",
      " [ 0.8008462 ]\n",
      " [-0.95512825]]  b: -0.30128098  loss: 0.48409203\n",
      "accuracy 0.7821229\n",
      "Iteration: 400000  W: [[ 1.2175218 ]\n",
      " [ 0.95536596]\n",
      " [-1.0816977 ]]  b: -0.19435251  loss: 0.4609026\n",
      "accuracy 0.7932961\n",
      "Iteration: 500000  W: [[ 1.3380808]\n",
      " [ 1.051148 ]\n",
      " [-1.1288431]]  b: -0.1303511  loss: 0.4518862\n",
      "accuracy 0.82122904\n",
      "Iteration: 600000  W: [[ 1.4194533]\n",
      " [ 1.1168014]\n",
      " [-1.1611438]]  b: -0.090922125  loss: 0.44677916\n",
      "accuracy 0.82122904\n",
      "Iteration: 700000  W: [[ 1.4807997]\n",
      " [ 1.1653496]\n",
      " [-1.1923735]]  b: -0.062061608  loss: 0.44322568\n",
      "accuracy 0.82122904\n",
      "Iteration: 800000  W: [[ 1.5306638]\n",
      " [ 1.2012258]\n",
      " [-1.2280161]]  b: -0.03670553  loss: 0.44045645\n",
      "accuracy 0.82122904\n",
      "Iteration: 900000  W: [[ 1.5711912]\n",
      " [ 1.2290846]\n",
      " [-1.2637789]]  b: -0.017990492  loss: 0.43841875\n",
      "accuracy 0.82122904\n"
     ]
    }
   ],
   "source": [
    "#adding hidden layer\n",
    "features = 7\n",
    "hidden_layer_nodes = 3\n",
    "x = tf.placeholder(tf.float32, [None, features])\n",
    "y_ = tf.placeholder(tf.float32, [None, 1])\n",
    "W1 = tf.Variable(tf.truncated_normal([features,hidden_layer_nodes], stddev=0.1))\n",
    "b1 = tf.Variable(tf.constant(0.1, shape=[hidden_layer_nodes]))\n",
    "z1 = tf.add(tf.matmul(x,W1),b1)\n",
    "a1 = tf.nn.relu(z1)\n",
    "W2 = tf.Variable(tf.truncated_normal([hidden_layer_nodes,1], stddev=0.1))\n",
    "b2 = tf.Variable(0.)\n",
    "z2 = tf.matmul(a1,W2) + b2\n",
    "y = 1 / (1.0 + tf.exp(-z2))\n",
    "loss = tf.reduce_mean(-(y_ * tf.log(y) + (1 - y_) * tf.log( 1 - y)))\n",
    "\n",
    "prediction3 = tf.round(y)\n",
    "correct3 = tf.cast(tf.equal(prediction3, y_), dtype=tf.float32)\n",
    "accuracy3 = tf.reduce_mean(correct3)\n",
    "\n",
    "\n",
    "update = tf.train.GradientDescentOptimizer(0.0001).minimize(loss)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(0,1000000):\n",
    "    sess.run(update, feed_dict = {x:x_train, y_:y_train})\n",
    "    trainAcc3 = sess.run(accuracy3, feed_dict={x: x_test, y_: y_test})\n",
    "    if i % 100000 == 0 :\n",
    "        print('Iteration:' , i , ' W:' , sess.run(W2) , ' b:' , sess.run(b2), ' loss:', loss.eval(session=sess, feed_dict = {x:x_train, y_:y_train}))\n",
    "        print('accuracy',trainAcc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 535 samples, validate on 179 samples\n",
      "535/535 [==============================] - 8s 14ms/sample - loss: 0.7726 - acc: 0.5813 - val_loss: 0.6127 - val_acc: 0.6257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2db208e8b88>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "#input_dim is the Size of the vocabulary\n",
    "#output_dim is the Dimension of the dense embedding.\n",
    "model.add(layers.Embedding(input_dim=535, output_dim=5))\n",
    "\n",
    "# Add a LSTM layer with 64 internal units.\n",
    "model.add(layers.LSTM(64))\n",
    "\n",
    "# Add a Dense layer with 5 units.\n",
    "model.add(layers.Dense(5))\n",
    "\n",
    "# Add an Activation layers 'relu'\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train, validation_data=(x_test, y_test), batch_size=1, epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
